{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Kp-by__XQZKm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score, accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error, f1_score, accuracy_score, recall_score\n",
        "from sklearn.cluster import KMeans\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "u1SqPdChQhh-",
        "outputId": "c78e17a0-4caf-452d-d302-c3cdfdb9c87e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataset/creditcard.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKnd2ckPQvEn",
        "outputId": "1b0cdf13-1484-4190-f876-f5f27a8de4d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5pu6qVhQv-a",
        "outputId": "652356cd-4968-4918-cb13-fd49667cdbb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Persentage of Y: \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Class\n",
              "0    99.827251\n",
              "1     0.172749\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Persentage of Y: \\n\")\n",
        "data['Class'].value_counts()/len(data['Class'])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7rfhwB-QyPb",
        "outputId": "f16929ae-8af5-4262-de3a-be287e723811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data imbalance ratio:  0.0017304750013189597\n"
          ]
        }
      ],
      "source": [
        "print(\"Data imbalance ratio: \" ,492/284315 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PuJfvTrDQ0a9"
      },
      "outputs": [],
      "source": [
        "y = data['Class']\n",
        "X=data.drop('Class', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FRKlEhFjQ41k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Utility functions\n",
        "def stats_mv(X):\n",
        "    # Implement missing value statistics\n",
        "    return np.sum(np.isnan(X), axis=0)\n",
        "\n",
        "def corr_ana(X):\n",
        "    # Implement correlation analysis\n",
        "    return np.corrcoef(X, rowvar=False)\n",
        "\n",
        "def cpd_group(Fm, Fc):\n",
        "    # Implement compound grouping\n",
        "    Gm = np.where(Fm > 0)[0]\n",
        "    Gc = np.where(abs(Fc) > 0.8)  # Example threshold for high correlation\n",
        "    return Gm, Gc\n",
        "\n",
        "def update_feature_count(X):\n",
        "    # Implement feature count updating\n",
        "    return X.shape[1]\n",
        "\n",
        "def KMeans_plus_plus(X, n_clusters):\n",
        "    # Implement K-Means++ clustering\n",
        "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10).fit(X)\n",
        "    return kmeans.cluster_centers_, kmeans.labels_\n",
        "\n",
        "def construct_spiral(Ccen, X_fraud):\n",
        "    # Extract center coordinates\n",
        "    x_center, y_center = Ccen\n",
        "\n",
        "    # Extract coordinates of fraud data\n",
        "    x_fraud, y_fraud = X_fraud\n",
        "\n",
        "    # Calculate distances from center to fraud data points\n",
        "    distances = np.sqrt((x_fraud - x_center) ** 2 + (y_fraud - y_center) ** 2)\n",
        "\n",
        "    # Generate angles for spiral curve based on distances\n",
        "    angles = distances * 2 * np.pi\n",
        "\n",
        "    # Generate spiral curve coordinates\n",
        "    x_spiral = x_center + distances * np.cos(angles)\n",
        "    y_spiral = y_center + distances * np.sin(angles)\n",
        "\n",
        "    return x_spiral, y_spiral\n",
        "\n",
        "def map_to_linear_space(Artisam):\n",
        "    linear_space_samples = []\n",
        "    for sample in Artisam:\n",
        "        if len(sample) > 0:\n",
        "            linear_space_samples.append(np.concatenate(sample, axis=1))\n",
        "\n",
        "    if len(linear_space_samples) > 0:\n",
        "        return np.concatenate(linear_space_samples)\n",
        "    else:\n",
        "        return np.array([])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jbeCJE8SQ8r7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CGEA (Compound Grouping Elimination Algorithm)\n",
        "# Step 1: Group features by missing values\n",
        "Fm = stats_mv(X)\n",
        "\n",
        "# Step 2: Group features by correlation\n",
        "Fc = corr_ana(X)\n",
        "Gm, Gc = cpd_group(Fm, Fc)\n",
        "\n",
        "# Step 3: Eliminate redundant features\n",
        "Fres = []\n",
        "N_f_amt, N_f_max = 0, 0\n",
        "for i in range(len(Gm)):\n",
        "    for j in range(len(Gc)):\n",
        "        N_f_amt = update_feature_count(X_train)\n",
        "        if N_f_amt >= N_f_max:\n",
        "            N_f_max = N_f_amt\n",
        "            Fres.append(Gc[j])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV0SIoL_Q_J-",
        "outputId": "87493f98-d706-4fd3-976e-308c987f4c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011787 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7650\n",
            "[LightGBM] [Info] Number of data points in the train set: 213605, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 0.001774\n"
          ]
        }
      ],
      "source": [
        "# MSEFBoost (Multifactor Synchronous Embedding Feature Boosting)\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Train decision tree regression model\n",
        "dtr = XGBClassifier()\n",
        "dtr.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = dtr.predict(X_train)\n",
        "\n",
        "# Calculate AUC and MSE\n",
        "VAUC = roc_auc_score(y_train, y_pred)\n",
        "VMSE = mean_squared_error(y_train, y_pred)\n",
        "VAMsub = VAUC - VMSE\n",
        "\n",
        "# Train LightGBM classifier\n",
        "lgbm = LGBMRegressor()\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = lgbm.feature_importances_\n",
        "\n",
        "# Calculate metamorphic factor\n",
        "meFac = feature_importances / sum(feature_importances) + (VAUC - VMSE) ** -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4k-9G2UBRGzA"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool, cpu_count\n",
        "import numpy as np\n",
        "\n",
        "# Function to construct spiral model for a given cluster\n",
        "def construct_spiral_model(args):\n",
        "    cluster_index, cluster_data, cluster_label = args\n",
        "    Min_prop = sum(cluster_label == 1) / sum(y_train == 1)\n",
        "    NC_count = int(Min_prop * Nsample)\n",
        "    if Min_prop == 0:\n",
        "        return np.array([])\n",
        "    spiral_samples = []\n",
        "    for _ in range(NC_count):\n",
        "        Z = construct_spiral(Ccen[cluster_index], [cluster_data[:, 0], cluster_data[:, 1]])\n",
        "        X_new = np.sin(Z) * Z\n",
        "        Y_new = np.cos(Z) * Z\n",
        "        spiral_samples.append([X_new, Y_new, Z])\n",
        "    return np.array(spiral_samples)\n",
        "\n",
        "# SOBT (Spiral Oversampling Balancing Technique)\n",
        "# Step 1: Clustering\n",
        "n_clusters = 2\n",
        "Ccen, Ctag = KMeans_plus_plus(X_train, n_clusters)\n",
        "\n",
        "# Step 2: Construct 3D spiral models in parallel\n",
        "Nsample = sum(y_train == 1) - sum(y_train == 0)\n",
        "num_workers = cpu_count()\n",
        "pool = Pool(processes=num_workers)\n",
        "args_list = [(i, X_train[Ctag == i], y_train[Ctag == i]) for i in range(len(Ccen))]\n",
        "spiral_samples_list = pool.map(construct_spiral_model, args_list)\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Flatten the list of lists\n",
        "Artisam = np.concatenate(spiral_samples_list, axis=0)\n",
        "\n",
        "# Step 3: Generate artificial samples\n",
        "Samplere = map_to_linear_space(Artisam)\n",
        "\n",
        "# Check if Samplere is one-dimensional and reshape if necessary\n",
        "if Samplere.ndim == 1:\n",
        "    Samplere = Samplere.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of Samplere and reshape if necessary\n",
        "if Samplere.shape[1] != X_train.shape[1]:\n",
        "    Samplere = Samplere.reshape(-1, X_train.shape[1])\n",
        "\n",
        "# Step 4: Combine artificial samples with original data for oversampling\n",
        "X_SOBT_Oversampled = np.concatenate((X_train, Samplere), axis=0)\n",
        "Y_SOBT_Oversampled = np.concatenate((y_train, np.ones(len(Samplere))))\n",
        "\n",
        "# Feature boosting on oversampled data\n",
        "X_SOBT_boosted = X_SOBT_Oversampled * meFac\n",
        "Y_SOBT_boosted = Y_SOBT_Oversampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp2z2i-oU1pB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the oversampled data into train and test sets\n",
        "X_train_SOBT_oversampled, X_test_SOBT_oversampled, y_train_SOBT_oversampled, y_test_SOBT_oversampled = train_test_split(X_SOBT_Oversampled, Y_SOBT_Oversampled, test_size=0.25, random_state=42)\n",
        "\n",
        "# Split the boosted data into train and test sets\n",
        "X_train_SOBT_boosted, X_test_SOBT_boosted, y_train_SOBT_boosted, y_test_SOBT_boosted = train_test_split(X_SOBT_boosted, Y_SOBT_boosted, test_size=0.25, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYnac_K8RJMp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnUcyWJkUaY9"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    g_mean = (recall * specificity) ** 0.5\n",
        "\n",
        "    return accuracy, precision, recall, f1, auc, g_mean\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuQuipKVVks8",
        "outputId": "06dea831-f3a5-47ab-ba93-50895655a154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 18, number of negative: 4466\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7650\n",
            "[LightGBM] [Info] Number of data points in the train set: 4484, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004014 -> initscore=-5.513877\n",
            "[LightGBM] [Info] Start training from score -5.513877\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "lgbm_model_oversampled = LGBMClassifier()\n",
        "rf_model_oversampled = RandomForestClassifier()\n",
        "\n",
        "# Evaluate LightGBM model for oversampled data\n",
        "lgbm_metrics_oversampled = evaluate_model(lgbm_model_oversampled, X_train_SOBT_oversampled, y_train_SOBT_oversampled, X_test_SOBT_oversampled, y_test_SOBT_oversampled)\n",
        "\n",
        "# Evaluate Random Forest model for oversampled data\n",
        "rf_metrics_oversampled = evaluate_model(rf_model_oversampled, X_train_SOBT_oversampled, y_train_SOBT_oversampled, X_test_SOBT_oversampled, y_test_SOBT_oversampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZLDe4uzVnwN",
        "outputId": "8295f5c0-22a3-46d6-e8d9-872a8acdb0eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 18, number of negative: 4466\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7650\n",
            "[LightGBM] [Info] Number of data points in the train set: 4484, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004014 -> initscore=-5.513877\n",
            "[LightGBM] [Info] Start training from score -5.513877\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "lgbm_model_boosted = LGBMClassifier()\n",
        "rf_model_boosted = RandomForestClassifier()\n",
        "\n",
        "# Evaluate LightGBM model for boosted data\n",
        "lgbm_metrics_boosted = evaluate_model(lgbm_model_boosted, X_train_SOBT_boosted, y_train_SOBT_boosted, X_test_SOBT_boosted, y_test_SOBT_boosted)\n",
        "\n",
        "# Evaluate Random Forest model for boosted data\n",
        "rf_metrics_boosted = evaluate_model(rf_model_boosted, X_train_SOBT_boosted, y_train_SOBT_boosted, X_test_SOBT_boosted, y_test_SOBT_boosted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctzao_KVV4p9",
        "outputId": "e96c2beb-9bbd-4bf4-ca29-9879f047a081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for oversampled data:\n",
            "LightGBM: Accuracy: 0.98, Precision: 0.11, Recall: 0.60, F1-score: 0.19, AUC: 0.73, G-mean: 0.77\n",
            "Random Forest: Accuracy: 1.00, Precision: 1.00, Recall: 0.80, F1-score: 0.89, AUC: 1.00, G-mean: 0.89\n",
            "Metrics for boosted data:\n",
            "LightGBM: Accuracy: 0.98, Precision: 0.11, Recall: 0.60, F1-score: 0.19, AUC: 0.73, G-mean: 0.77\n",
            "Random Forest: Accuracy: 1.00, Precision: 1.00, Recall: 0.80, F1-score: 0.89, AUC: 1.00, G-mean: 0.89\n"
          ]
        }
      ],
      "source": [
        "# Print evaluation metrics for oversampled data\n",
        "print(\"Metrics for oversampled data:\")\n",
        "print(\"LightGBM: Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}, F1-score: {:.2f}, AUC: {:.2f}, G-mean: {:.2f}\".format(*lgbm_metrics_oversampled))\n",
        "print(\"Random Forest: Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}, F1-score: {:.2f}, AUC: {:.2f}, G-mean: {:.2f}\".format(*rf_metrics_oversampled))\n",
        "\n",
        "# Print evaluation metrics for boosted data\n",
        "print(\"Metrics for boosted data:\")\n",
        "print(\"LightGBM: Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}, F1-score: {:.2f}, AUC: {:.2f}, G-mean: {:.2f}\".format(*lgbm_metrics_boosted))\n",
        "print(\"Random Forest: Accuracy: {:.2f}, Precision: {:.2f}, Recall: {:.2f}, F1-score: {:.2f}, AUC: {:.2f}, G-mean: {:.2f}\".format(*rf_metrics_boosted))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpjsfNVSWBff"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
